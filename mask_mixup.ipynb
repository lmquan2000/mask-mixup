{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import albumentations as A\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "from PIL import Image, ImageDraw\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),\n",
    "          (0, 255, 255), (255, 0, 255), (0, 0, 0), (255, 255, 255)]\n",
    "random.seed(2021)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "with open('./MERGE_OCEAN/Annotations/merge_ocean_train.json', 'r') as json_file:\n",
    "    train_anno = json.load(json_file)\n",
    "json_file.close()\n",
    "with open('./MERGE_OCEAN/Annotations/merge_ocean_test.json', 'r') as json_file:\n",
    "    test_anno = json.load(json_file)\n",
    "json_file.close()\n",
    "with open('../inference/point_rend_r50.json', 'r') as json_file:\n",
    "    pred = json.load(json_file)\n",
    "json_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "list_images = train_anno['images']\n",
    "list_names = [item['name'] for item in test_anno['categories']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def extract_polygons(annotations, img_id):\n",
    "    list_poly = []\n",
    "    num_points = []\n",
    "    list_annos = []\n",
    "    tmp_annotations = deepcopy(annotations)\n",
    "    for ann in tmp_annotations:\n",
    "        image_id = ann['image_id']\n",
    "        if image_id == img_id:\n",
    "            sub_num_points = []\n",
    "            list_points = ann['segmentation']\n",
    "            for points in list_points:\n",
    "                points = [(int(points[2*i]), int(points[2*i+1])) for i in range(len(points)//2)]\n",
    "\n",
    "                sub_num_points.append(len(points))\n",
    "                list_poly.extend(points)\n",
    "            num_points.append(sub_num_points)\n",
    "            list_annos.append(deepcopy(ann))\n",
    "    return list_poly, num_points, list_annos\n",
    "\n",
    "def keypoint2polygons(keypoints, num_points):\n",
    "    start_idx = 0\n",
    "    list_polys = []\n",
    "    for sub_points in num_points:\n",
    "        sub_poly = []\n",
    "        for points in sub_points:\n",
    "            sub_poly.append(keypoints[start_idx:start_idx+points])\n",
    "            start_idx += points\n",
    "        \n",
    "        list_polys.append(sub_poly)\n",
    "    \n",
    "    return list_polys\n",
    "\n",
    "def visualize_polygons(img, list_polys):\n",
    "    for i, polys in enumerate(list_polys):\n",
    "        for poly in polys:\n",
    "            poly_np = np.array(poly)\n",
    "            img = cv2.polylines(img, np.int32([poly_np]), True, colors[i%len(colors)], 2)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "\n",
    "def get_iou(bb1, bb2):\n",
    "    \n",
    "    x_left = max(bb1[0], bb2[0])\n",
    "    y_top = max(bb1[1], bb2[1])\n",
    "    x_right = min(bb1[2], bb2[2])\n",
    "    y_bottom = min(bb1[3], bb2[3])\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "        return 0.0\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    bb1_area = (bb1[2] - bb1[0]) * (bb1[3] - bb1[1])\n",
    "    bb2_area = (bb2[2] - bb2[0]) * (bb2[3] - bb2[1])\n",
    "\n",
    "    iou = intersection_area / float(bb1_area + bb2_area - intersection_area)\n",
    "    return iou\n",
    "\n",
    "def get_confusion_matrix(gt, pred_list):\n",
    "    pred_label = []\n",
    "    gt_label = []\n",
    "    \n",
    "    for pred_ann in pred_list:\n",
    "        pred_id = pred_ann['image_id']\n",
    "        for gt_ann in gt['annotations']:\n",
    "            gt_id = gt_ann['image_id']\n",
    "            if pred_id == gt_id:\n",
    "\n",
    "                pred_box = list(map(int,pred_ann['bbox']))\n",
    "                gt_box = list(map(int, gt_ann['bbox']))\n",
    "                x1,y1,w,h = gt_box\n",
    "                x2 = x1+w; y2 = y1+h\n",
    "        \n",
    "                iou = get_iou(pred_box, [x1,y1,x2,y2])\n",
    "                if iou > 0.5:\n",
    "                    pred_label.append(pred_ann['category_id'])\n",
    "                    gt_label.append(gt_ann['category_id'])\n",
    "    \n",
    "    return confusion_matrix(gt_label, pred_label)\n",
    "\n",
    "def get_miss_classify(cm: np.array)->list:\n",
    "    miscls = []\n",
    "    for i in range(cm.shape[0]):\n",
    "        idx = -1\n",
    "        best = -1\n",
    "        for j in range(cm.shape[1]):\n",
    "            if i!=j and cm[i][j] > best:\n",
    "                best = cm[i][j]\n",
    "                idx = j\n",
    "        if cm[i][idx]>10:\n",
    "            miscls.append(set([list_names[i], list_names[idx]]))\n",
    "    miscls = np.unique(np.array(miscls))    \n",
    "    return miscls\n",
    "\n",
    "def get_miss_classify_plus(cm: np.array)->list:\n",
    "    miscls = []\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            if i!=j and cm[i][j] > 10:\n",
    "                miscls.append(set([list_names[i], list_names[j]]))\n",
    "    \n",
    "    miscls = np.unique(np.array(miscls))    \n",
    "    return miscls\n",
    "\n",
    "def get_class_samples(list_images: str, class_name: str, num_samples: int) -> list:\n",
    "    sub_images = list(filter(lambda s: s['file_name'].split('/')[-2] == class_name, list_images))\n",
    "    if num_samples > len(sub_images):\n",
    "        num_samples = len(sub_images)\n",
    "    return random.sample(sub_images, num_samples)\n",
    "\n",
    "def polygon2segmentation(list_polygon: list)->list:\n",
    "    list_segment = []\n",
    "    for poly in list_polygon:\n",
    "        segment = []\n",
    "        [segment.extend(list(point)) for point in poly]\n",
    "        list_segment.append(segment)\n",
    "    return list_segment\n",
    "\n",
    "def update_properties(ann: dict, img_shape: tuple, polygon: list, image_id: int)->dict:\n",
    "    mask_img = Image.new('L', img_shape, 0)\n",
    "    ann['segmentation'] = polygon2segmentation(polygon)\n",
    "    tmp_poly_list = []\n",
    "    [tmp_poly_list.append((int(point[0]), int(point[1]))) for point in polygon[0]]\n",
    "\n",
    "    ImageDraw.Draw(mask_img).polygon(tmp_poly_list, outline=1, fill=1)\n",
    "    ann['area'] = int(np.sum(np.array(mask_img)))\n",
    "    x1, x2 = np.min(np.array(tmp_poly_list)[:, 0]), np.max(np.array(tmp_poly_list)[:, 0])\n",
    "    y1, y2 = np.min(np.array(tmp_poly_list)[:, 1]), np.max(np.array(tmp_poly_list)[:, 1])\n",
    "    ann['bbox'] = list(map(int,[x1,y1,x2-x1,y2-y1]))\n",
    "    ann['image_id'] = image_id\n",
    "    return ann\n",
    "\n",
    "def mixup_image(img1: dict, img2: dict, new_image_id: int):\n",
    "    list_anno = []\n",
    "    image_anno = dict()\n",
    "    \n",
    "    poly1, num1, ann1 = extract_polygons(train_anno['annotations'], img1['id'])\n",
    "    poly2, num2, ann2 = extract_polygons(train_anno['annotations'], img2['id'])\n",
    "    w1, h1 = img1['width'], img1['height']\n",
    "    w2, h2 = img2['width'], img2['height']\n",
    "    W, H = int((w1+w2)/2), int((h1+h2)/2)\n",
    "    \n",
    "    image_anno['width'] = W\n",
    "    image_anno['height'] = H\n",
    "    image_anno['id'] = new_image_id\n",
    "    image_anno['file_name'] = '../MERGE_OCEAN/Train/MIXUP++/' + img1['file_name'].split('/')[-1].split('.')[0] + '&' + img2['file_name'].split('/')[-1].split('.')[0] + '.jpg'\n",
    "    \n",
    "    transform = A.Compose([\n",
    "        A.Resize(height=H, width=W)\n",
    "    ], keypoint_params=A.KeypointParams(format='xy'))\n",
    "    \n",
    "    image1 = cv2.imread(img1['file_name'][1:])\n",
    "    image2 = cv2.imread(img2['file_name'][1:])\n",
    "    \n",
    "    transformed1 = transform(image=image1, keypoints=poly1)\n",
    "    transformed_image1 = transformed1['image']\n",
    "    transformed_keypoints1 = transformed1['keypoints']\n",
    "\n",
    "    transformed2 = transform(image=image2, keypoints=poly2)\n",
    "    transformed_image2 = transformed2['image']\n",
    "    transformed_keypoints2 = transformed2['keypoints']\n",
    "    \n",
    "    transformed_img = transformed_image1*0.5 + transformed_image2*0.5\n",
    "    \n",
    "    transformed_poly1 = keypoint2polygons(transformed_keypoints1, num1)\n",
    "    transformed_poly2 = keypoint2polygons(transformed_keypoints2, num2)\n",
    "    \n",
    "    for i in range(len(ann1)):\n",
    "        ann1[i] = update_properties(ann1[i], (W,H), transformed_poly1[i], new_image_id)\n",
    "        list_anno.append(ann1[i])\n",
    "    for i in range(len(ann2)):\n",
    "        ann2[i] = update_properties(ann2[i], (W,H), transformed_poly2[i], new_image_id)\n",
    "        list_anno.append(ann2[i])\n",
    "    \n",
    "    return transformed_img, transformed_poly1 + transformed_poly2, image_anno, list_anno"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "cm = get_confusion_matrix(test_anno, pred)\n",
    "miscls = get_miss_classify_plus(cm)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "transformed_annotations = dict()\n",
    "transformed_annotations['categories'] = deepcopy(train_anno['categories'])\n",
    "transformed_annotations['images'] = []\n",
    "transformed_annotations['annotations'] = []\n",
    "count_img = 0\n",
    "count_ins = 0\n",
    "num_sample = 10\n",
    "for mis_tuple in tqdm(miscls):\n",
    "    \n",
    "    first_samples = get_class_samples(list_images, list(mis_tuple)[0], num_sample)\n",
    "    second_samples = get_class_samples(list_images, list(mis_tuple)[1], num_sample)\n",
    "    \n",
    "    for i in range(min(len(first_samples), len(second_samples))):\n",
    "        transformed_img, polygon, transformed_imganno, transformed_anno = mixup_image(first_samples[i], second_samples[i], count_img)\n",
    "        count_img += 1\n",
    "        transformed_annotations['images'].append(transformed_imganno)\n",
    "        \n",
    "        for j in range(len(transformed_anno)):\n",
    "            transformed_anno[j]['id'] = count_ins\n",
    "            count_ins += 1\n",
    "        \n",
    "        transformed_annotations['annotations'].extend(transformed_anno)\n",
    "        \n",
    "        cv2.imwrite(transformed_imganno['file_name'][1:], transformed_img)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111156f3fbd54e83b0f7fc84894e5733"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "with open('./MERGE_OCEAN/Annotations/augmentation++.json', 'w') as json_file:\n",
    "    json.dump(transformed_annotations, json_file)\n",
    "json_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}